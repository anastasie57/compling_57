## Задание

### **Тема: Мешок слов и классификация твитов**

#### **Дедлайн**: 16.02.25 23:59

### Задание
#### Пункт 1: Кастомная токенизация в векторизаторе
У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию.

Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите любой классификатор с каждым из векторизаторов. Сравните метрики и выберите победителя. В вашей тетрадке должен быть код обучения и все метрики.

    
```python
import pandas as pd
data = pd.read_csv('labeled.csv')

# ваш код
```

#### Пункт 2: Beam Search
Обучите 2 любых разных классификатора из тетрадки с теорией. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты — какие тексты совпадают, какие отличаются, правда ли тексты токсичные?

***Требования к моделям:**   
а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  
б) у векторайзера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  
в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  
г) f1-мера каждого из классификаторов должна быть минимум 0.75  

*random_seed не считается за параметр

**Что сдать**
1. Тетрадка с кодом в формате IPYNB

#### Критерии оценки
Является обязательным оформление домашней работы в Jupyter Notebook с ответами на вопросы, комментариями и по PEP-8.
<table>
    <tr><th>Макс. балл</th><th>Критерий</th></tr>
    <tr><td>4</td><td>пункт 1</td></tr>    
    <tr><td>6</td><td>пункт 2</td></tr>    
</table>
